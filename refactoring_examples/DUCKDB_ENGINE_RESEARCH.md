# DuckDB-Engine Research: SQLAlchemy Support for DuckDB

**Date:** October 7, 2025
**Finding:** SQLAlchemy Inspector WORKS with DuckDB - This changes our refactoring plan!

---

## ðŸŽ‰ Major Discovery

**Mock Spark already has `duckdb-engine>=0.15.0` installed!**

This provides **much better SQLAlchemy support** than we initially thought. We can eliminate MORE raw SQL than expected!

---

## âœ… What Works (Tested and Confirmed)

### 1. SQLAlchemy Engine Creation
```python
from sqlalchemy import create_engine

# In-memory database
engine = create_engine('duckdb:///:memory:')

# File-based database
engine = create_engine('duckdb:///path/to/database.db')
```
**Status:** âœ… Works perfectly

---

### 2. SQLAlchemy Inspector (Metadata Queries)

#### Get Table Names
```python
from sqlalchemy import inspect

inspector = inspect(engine)
tables = inspector.get_table_names()
# Returns: ['table1', 'table2', 'table3']
```
**Status:** âœ… **WORKS!** Can replace `SHOW TABLES`

#### Check Table Exists
```python
exists = inspector.has_table('users')
# Returns: True or False
```
**Status:** âœ… **WORKS!** Can replace `SELECT * FROM ... LIMIT 1`

#### Get Column Metadata
```python
columns = inspector.get_columns('users')
# Returns: [
#   {'name': 'id', 'type': INTEGER, 'nullable': True},
#   {'name': 'name', 'type': VARCHAR, 'nullable': True}
# ]
```
**Status:** âœ… **WORKS!** Can replace `DESCRIBE table`

#### Get Schema Names
```python
schemas = inspector.get_schema_names()
# Returns: ['memory.main', 'system.information_schema', 'temp.main']
```
**Status:** âœ… **WORKS!**

---

### 3. Table Reflection (autoload_with)
```python
from sqlalchemy import Table, MetaData

metadata = MetaData()
reflected_table = Table('users', metadata, autoload_with=engine)

# Access columns
for col in reflected_table.columns:
    print(f"{col.name}: {col.type}")
```
**Status:** âœ… **WORKS!** Can dynamically load existing tables

**Note:** Warning about index reflection (not yet supported), but this doesn't affect basic usage.

---

### 4. Standard SQLAlchemy Core Operations
```python
from sqlalchemy import Table, Column, Integer, String, MetaData, select, insert

# Create table
metadata = MetaData()
users = Table('users', metadata,
    Column('id', Integer, primary_key=True),
    Column('name', String)
)
users.create(engine)

# Insert
with engine.connect() as conn:
    stmt = insert(users).values(id=1, name='Alice')
    conn.execute(stmt)
    conn.commit()

# Select
with engine.connect() as conn:
    stmt = select(users).where(users.c.id > 0)
    results = conn.execute(stmt).all()
```
**Status:** âœ… **WORKS!** Full SQLAlchemy Core support

---

### 5. SQLModel Support
```python
from sqlmodel import SQLModel, Field, Session, create_engine, select

class User(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    name: str

engine = create_engine('duckdb:///:memory:')
SQLModel.metadata.create_all(engine)

with Session(engine) as session:
    user = User(name="Alice")
    session.add(user)
    session.commit()

    results = session.exec(select(User)).all()
```
**Status:** âœ… **WORKS!** Full SQLModel support

---

## âš ï¸ Known Limitations

### 1. Index Reflection
```python
# Warning: duckdb-engine doesn't yet support reflection on indices
```
**Impact:** Low - Mock Spark doesn't heavily use indexes

### 2. Some PostgreSQL-Specific Types
- `JSONB` â†’ Use `VARCHAR` or `STRUCT` instead
- `ENUM` â†’ Partial support, may have issues
- `SERIAL` â†’ Use `INTEGER` with `primary_key=True`

**Impact:** Low - Mock Spark uses basic types (INTEGER, VARCHAR, DOUBLE, BOOLEAN)

### 3. Foreign Key Constraints
- Not fully implemented in DuckDB
- Can define but won't enforce

**Impact:** None - Mock Spark doesn't use foreign keys

---

## ðŸŽ¯ Impact on Refactoring Plan

### MAJOR UPDATE: Can Eliminate Even MORE Raw SQL!

#### Before Research (Pessimistic)
```python
# âœ‹ THOUGHT WE NEEDED RAW SQL
def list_tables(self):
    """List all tables in schema."""
    # âœ‹ No SQLAlchemy equivalent
    result = self.connection.execute("SHOW TABLES").fetchall()
    return [row[0] for row in result]
```

#### After Research (Optimistic)
```python
# âœ… CAN USE SQLALCHEMY!
def list_tables(self):
    """List all tables using SQLAlchemy Inspector."""
    from sqlalchemy import inspect
    inspector = inspect(self.engine)
    return inspector.get_table_names()
```

---

## ðŸ“Š Updated Coverage Estimate

### Original Estimate (Before Research)
- SQLModel: 80%
- SQLAlchemy Core: 15%
- Raw SQL: 5%

### New Estimate (After Research)
- **SQLModel: 85%** (can use for more operations)
- **SQLAlchemy Core: 13%** (dynamic schemas)
- **Raw SQL: 2%** (only DuckDB-specific extensions and SQL parser)

**We can eliminate an additional ~3% of raw SQL!**

---

## âœ‹ What STILL Requires Raw SQL (Reduced List)

### 1. DuckDB Extensions Only
```python
# âœ‹ STILL NEED RAW SQL: DuckDB-specific
connection.execute(text("INSTALL parquet"))
connection.execute(text("LOAD parquet"))
connection.execute(text("PRAGMA memory_limit='4GB'"))
```

### 2. SQL Parser Implementation
```python
# âœ‹ STILL NEED RAW SQL: Implementing SQL engine
def execute_sql(query: str):
    # User provides arbitrary SQL, we parse and execute
    return connection.execute(text(query))
```

### 3. DuckDB-Specific File Reading
```python
# âœ‹ STILL NEED RAW SQL: DuckDB-specific syntax
result = connection.execute(text("SELECT * FROM 'data.parquet'"))
result = connection.execute(text("SELECT * FROM read_csv_auto('data.csv')"))
```

### 4. Performance-Critical Bulk Operations (Optional)
```python
# âš¡ RAW SQL FASTER: But could use SQLAlchemy if preferred
if len(data) > 10000:
    # Raw SQL 2-5x faster for very large batches
    connection.executemany("INSERT INTO ...", values)
```

---

## ðŸ”„ Updated File-by-File Changes

### `mock_spark/storage/backends/duckdb.py`

#### Before Research
- Refactor: 70%
- Keep raw SQL: 30% (metadata, extensions, bulk)

#### After Research
- **Refactor: 95%!**
- **Keep raw SQL: 5%** (only extensions)

```python
from sqlalchemy import inspect, create_engine

class DuckDBStorageManager:
    def __init__(self, db_path=None):
        # Use SQLAlchemy engine everywhere
        if db_path:
            self.engine = create_engine(f'duckdb:///{db_path}')
        else:
            self.engine = create_engine('duckdb:///:memory:')

    def list_tables(self, schema="default"):
        """âœ… USE SQLALCHEMY: Inspector works!"""
        inspector = inspect(self.engine)
        return inspector.get_table_names()

    def table_exists(self, schema, table):
        """âœ… USE SQLALCHEMY: has_table works!"""
        inspector = inspect(self.engine)
        return inspector.has_table(table)

    def get_table_schema(self, schema, table):
        """âœ… USE SQLALCHEMY: get_columns works!"""
        inspector = inspect(self.engine)
        columns = inspector.get_columns(table)
        return self._convert_to_mock_schema(columns)

    def _enable_extensions(self):
        """âœ‹ KEEP RAW SQL: DuckDB-specific only"""
        try:
            with self.engine.connect() as conn:
                conn.execute(text("INSTALL sqlite"))
                conn.execute(text("LOAD sqlite"))
        except:
            pass
```

---

## ðŸ“‹ Code Examples: Before vs After

### Example 1: List Tables

#### Before (Raw SQL)
```python
def list_tables(self) -> List[str]:
    """âœ‹ Thought we needed raw SQL."""
    try:
        result = self.connection.execute("SHOW TABLES").fetchall()
        return [row[0] for row in result]
    except:
        return []
```

#### After (SQLAlchemy)
```python
def list_tables(self) -> List[str]:
    """âœ… Use SQLAlchemy Inspector!"""
    from sqlalchemy import inspect
    inspector = inspect(self.engine)
    return inspector.get_table_names()
```

---

### Example 2: Table Exists

#### Before (Raw SQL)
```python
def table_exists(self, table: str) -> bool:
    """âœ‹ Thought we needed raw SQL."""
    try:
        self.connection.execute(f"SELECT 1 FROM {table} LIMIT 1")
        return True
    except:
        return False
```

#### After (SQLAlchemy)
```python
def table_exists(self, table: str) -> bool:
    """âœ… Use Inspector!"""
    from sqlalchemy import inspect
    inspector = inspect(self.engine)
    return inspector.has_table(table)
```

---

### Example 3: Get Column Info

#### Before (Raw SQL)
```python
def get_columns(self, table: str):
    """âœ‹ Thought we needed DESCRIBE."""
    result = self.connection.execute(f"DESCRIBE {table}").fetchall()
    return [{'name': row[0], 'type': row[1]} for row in result]
```

#### After (SQLAlchemy)
```python
def get_columns(self, table: str):
    """âœ… Use Inspector!"""
    from sqlalchemy import inspect
    inspector = inspect(self.engine)
    return inspector.get_columns(table)
```

---

### Example 4: Dynamic Table Loading

#### Before (Manual Creation)
```python
def get_table(self, name: str):
    """Had to manually build Table object."""
    columns = self._get_columns_from_raw_sql(name)
    table = Table(name, metadata, *self._build_columns(columns))
    return table
```

#### After (Reflection)
```python
def get_table(self, name: str):
    """âœ… Use autoload_with!"""
    from sqlalchemy import Table, MetaData
    metadata = MetaData()
    return Table(name, metadata, autoload_with=self.engine)
```

---

## ðŸš€ Updated Implementation Plan

### Phase 1: Quick Wins (1-2 weeks) - NO CHANGE
1. `sqlmodel_materializer.py` âœ…
2. `export.py` âœ…
3. `duckdb_materializer.py` âœ…

### Phase 2: Core Infrastructure (1-2 weeks) - MUCH EASIER NOW!
4. **`storage/backends/duckdb.py`** âœ… **95% refactor** (was 70%)
   - Replace `SHOW TABLES` â†’ `inspector.get_table_names()`
   - Replace `DESCRIBE` â†’ `inspector.get_columns()`
   - Replace table existence checks â†’ `inspector.has_table()`
   - Keep only DuckDB extensions as raw SQL

5. `sql_builder.py` âœ… 100% SQLAlchemy Core

### Phase 3: Testing (1 week)
- Test Inspector integration
- Verify metadata operations
- Performance benchmarks

### Total Time: **3-5 weeks** (unchanged, but LESS risk!)

---

## ðŸ§ª Testing Inspector Integration

### Test Script
```python
import pytest
from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, inspect, text

def test_inspector_list_tables():
    """Test Inspector can list tables."""
    engine = create_engine('duckdb:///:memory:')

    # Create test tables
    with engine.connect() as conn:
        conn.execute(text("CREATE TABLE users (id INTEGER)"))
        conn.execute(text("CREATE TABLE orders (id INTEGER)"))
        conn.commit()

    # Use Inspector
    inspector = inspect(engine)
    tables = inspector.get_table_names()

    assert 'users' in tables
    assert 'orders' in tables

def test_inspector_has_table():
    """Test Inspector can check table existence."""
    engine = create_engine('duckdb:///:memory:')
    metadata = MetaData()
    Table('test', metadata, Column('id', Integer)).create(engine)

    inspector = inspect(engine)
    assert inspector.has_table('test') is True
    assert inspector.has_table('nonexistent') is False

def test_inspector_get_columns():
    """Test Inspector can get column metadata."""
    engine = create_engine('duckdb:///:memory:')

    with engine.connect() as conn:
        conn.execute(text("CREATE TABLE products (id INTEGER, name VARCHAR, price DOUBLE)"))
        conn.commit()

    inspector = inspect(engine)
    columns = inspector.get_columns('products')

    assert len(columns) == 3
    assert columns[0]['name'] == 'id'
    assert str(columns[0]['type']) == 'INTEGER'

def test_table_reflection():
    """Test table reflection with autoload_with."""
    engine = create_engine('duckdb:///:memory:')

    # Create table
    with engine.connect() as conn:
        conn.execute(text("CREATE TABLE employees (id INTEGER, name VARCHAR, salary DOUBLE)"))
        conn.commit()

    # Reflect table
    metadata = MetaData()
    reflected = Table('employees', metadata, autoload_with=engine)

    assert 'id' in reflected.c
    assert 'name' in reflected.c
    assert 'salary' in reflected.c
```

---

## ðŸ“š Useful Resources

### Official Documentation
- **duckdb-engine GitHub**: https://github.com/Mause/duckdb_engine
- **MotherDuck SQLAlchemy Guide**: https://motherduck.com/docs/integrations/language-apis-and-drivers/python/sqlalchemy/
- **SQLAlchemy Inspector**: https://docs.sqlalchemy.org/en/20/core/reflection.html

### Installation
```bash
pip install duckdb-engine>=0.15.0  # Already in pyproject.toml!
```

### Connection Strings
```python
# In-memory
engine = create_engine('duckdb:///:memory:')

# File-based
engine = create_engine('duckdb:///path/to/db.duckdb')

# MotherDuck (cloud)
engine = create_engine('duckdb:///md:my_db?motherduck_token=TOKEN')
```

---

## âœ… Recommendations

### 1. Update Refactoring Plan
- âœ… Use Inspector for ALL metadata operations
- âœ… Use `autoload_with` for dynamic table loading
- âœ… Only keep raw SQL for extensions and SQL parser

### 2. Implement Helper Functions
```python
# mock_spark/storage/sqlalchemy_helpers.py
from sqlalchemy import inspect

def list_all_tables(engine):
    """Get all tables using Inspector."""
    inspector = inspect(engine)
    return inspector.get_table_names()

def table_exists(engine, table_name):
    """Check if table exists using Inspector."""
    inspector = inspect(engine)
    return inspector.has_table(table_name)

def get_table_metadata(engine, table_name):
    """Get table columns using Inspector."""
    inspector = inspect(engine)
    return inspector.get_columns(table_name)

def reflect_table(engine, table_name):
    """Dynamically load table using reflection."""
    from sqlalchemy import Table, MetaData
    metadata = MetaData()
    return Table(table_name, metadata, autoload_with=engine)
```

### 3. Update Documentation
- âœ… Document that metadata operations use Inspector
- âœ… Update `SQLMODEL_LIMITATIONS.md` to remove metadata from "must use raw SQL"
- âœ… Add examples of Inspector usage

---

## ðŸŽ¯ Conclusion

**Major Finding:** SQLAlchemy Inspector works excellently with DuckDB!

### Impact on Plan
- **MORE code can be refactored** (95% vs 70%)
- **FEWER raw SQL edge cases** (2% vs 5%)
- **EASIER implementation** (Inspector is cleaner than raw SQL)
- **BETTER maintainability** (standard SQLAlchemy patterns)

### Updated "Must Keep Raw SQL" List
1. âœ‹ DuckDB extensions (`INSTALL`, `LOAD`, `PRAGMA`)
2. âœ‹ SQL parser implementation (arbitrary user SQL)
3. âš¡ Optional: Bulk operations for performance (>10k rows)

### Everything Else Can Use SQLAlchemy!
- âœ… Table listing â†’ Inspector
- âœ… Table existence â†’ Inspector
- âœ… Column metadata â†’ Inspector
- âœ… Table reflection â†’ autoload_with
- âœ… CRUD operations â†’ SQLModel/SQLAlchemy Core

**This research significantly improves our refactoring plan!**

---

**Research Date:** October 7, 2025
**Tested with:** duckdb-engine 0.15.0, SQLAlchemy 2.0.0
**Confidence Level:** High (all features tested and confirmed)
