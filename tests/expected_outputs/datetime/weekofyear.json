{
  "test_id": "weekofyear",
  "pyspark_version": "3.5",
  "generated_at": "2025-10-25T20:19:09.604379",
  "input_data": [
    {
      "id": 1,
      "name": "Alice",
      "hire_date": "2020-01-15",
      "birth_date": "1990-05-20"
    },
    {
      "id": 2,
      "name": "Bob",
      "hire_date": "2019-03-10",
      "birth_date": "1985-12-03"
    },
    {
      "id": 3,
      "name": "Charlie",
      "hire_date": "2021-07-22",
      "birth_date": "1992-08-14"
    }
  ],
  "operation": "DataFrame operation: weekofyear",
  "expected_output": {
    "schema": {
      "field_count": 1,
      "field_names": [
        "weekofyear(hire_date)"
      ],
      "field_types": [
        "integer"
      ],
      "fields": [
        {
          "name": "weekofyear(hire_date)",
          "type": "integer",
          "nullable": true
        }
      ]
    },
    "data": [
      {
        "weekofyear(hire_date)": 3
      },
      {
        "weekofyear(hire_date)": 10
      },
      {
        "weekofyear(hire_date)": 29
      }
    ],
    "row_count": 3
  }
}