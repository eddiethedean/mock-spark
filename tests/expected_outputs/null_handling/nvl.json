{
  "test_id": "nvl",
  "pyspark_version": "3.5",
  "generated_at": "2025-10-25T20:18:50.135009",
  "input_data": [
    {
      "id": 1,
      "name": "Alice",
      "age": 25,
      "salary": 50000.0,
      "department": "IT"
    },
    {
      "id": 2,
      "name": null,
      "age": 30,
      "salary": null,
      "department": "HR"
    },
    {
      "id": 3,
      "name": "Charlie",
      "age": null,
      "salary": 70000.0,
      "department": null
    },
    {
      "id": 4,
      "name": "David",
      "age": 40,
      "salary": 80000.0,
      "department": "Finance"
    }
  ],
  "operation": "DataFrame operation: nvl",
  "expected_output": {
    "schema": {
      "field_count": 1,
      "field_names": [
        "coalesce(salary, 0)"
      ],
      "field_types": [
        "double"
      ],
      "fields": [
        {
          "name": "coalesce(salary, 0)",
          "type": "double",
          "nullable": false
        }
      ]
    },
    "data": [
      {
        "coalesce(salary, 0)": 50000.0
      },
      {
        "coalesce(salary, 0)": 0.0
      },
      {
        "coalesce(salary, 0)": 70000.0
      },
      {
        "coalesce(salary, 0)": 80000.0
      }
    ],
    "row_count": 4
  }
}